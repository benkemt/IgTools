{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARCH and GARCH Modeling\n",
    "\n",
    "## Introduction\n",
    "\n",
    "ARCH modeling, often referred to as ARCH (Autoregressive Conditional Heteroskedasticity) modeling, is a statistical technique used to model time series data with time-varying volatility. It is particularly useful in financial econometrics for modeling and forecasting the volatility of asset returns.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "1. **Heteroskedasticity**: This refers to the condition where the variance of the error terms in a regression model is not constant over time.\n",
    "2. **Autoregressive**: This indicates that the model uses past values of the variable to predict future values.\n",
    "\n",
    "## ARCH Model\n",
    "\n",
    "The ARCH model was introduced by Robert Engle in 1982. The basic idea is to model the variance of the current error term as a function of the squared error terms from previous periods.\n",
    "\n",
    "### Basic ARCH Model\n",
    "\n",
    "The basic ARCH(q) model can be described as follows:\n",
    "\n",
    "1. **Mean Equation**:\n",
    "   \n",
    "   $y_t = \\mu + \\epsilon_t$\n",
    "   \n",
    "   where $y_t$ is the time series value at time $t$ , $\\mu$ is the mean, and $\\epsilon_t$ is the error term (return residuals, with respect to a mean process)\n",
    "\n",
    "2. **Variance Equation**:\n",
    "   \n",
    "   $\\epsilon_t = \\sigma_t z_t$\n",
    "\n",
    "   $\\sigma_t^2 = \\alpha_0 + \\alpha_1 \\epsilon_{t-1}^2 + \\alpha_2 \\epsilon_{t-2}^2 + \\ldots + \\alpha_q \\epsilon_{t-q}^2 = \\alpha_0 +  \\sum_{i=1}^q  \\alpha_i \\epsilon_{t-i}^2$\n",
    "   \n",
    "   where  $\\sigma_t^2$ is the conditional variance at time $t$, $\\alpha_0,\\alpha_1 \\ldots \\alpha_q$ are parameters to be estimated, and $z_t$ is a white noise error term.\n",
    "\n",
    "## GARCH Model\n",
    "\n",
    "The Generalized ARCH (GARCH) model extends the ARCH model by including lagged values of the conditional variance. The GARCH(p, q) model can be described as:\n",
    "\n",
    "1. **Mean Equation**:\n",
    "\n",
    "   $y_t = \\mu + \\epsilon_t$\n",
    "\n",
    "2. **Variance Equation**:\n",
    "\n",
    "   $\\epsilon_t = \\sigma_t z_t$\n",
    "   \n",
    "   $\\sigma_t^2 = \\alpha_0 + \\sum_{i=1}^{q} \\alpha_i \\epsilon_{t-i}^2 + \\sum_{j=1}^{p} \\beta_j \\sigma_{t-j}^2$\n",
    "\n",
    "   where $\\beta_j$ are additional parameters to be estimated.\n",
    "\n",
    "## Applications\n",
    "\n",
    "- **Financial Markets**: Modeling and forecasting the volatility of stock returns, exchange rates, and other financial assets.\n",
    "- **Risk Management**: Estimating Value at Risk (VaR) and other risk metrics.\n",
    "- **Econometrics**: Analyzing economic time series data with changing volatility.\n",
    "\n",
    "## Implementation\n",
    "\n",
    "ARCH and GARCH models can be implemented using various statistical software packages, such as R, Python (with libraries like `arch` and `statsmodels`), and others.\n",
    "\n",
    "### Example in Python\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from arch import arch_model\n",
    "\n",
    "# Generate some synthetic data\n",
    "np.random.seed(42)\n",
    "returns = np.random.normal(0, 1, 1000)\n",
    "\n",
    "# Fit an ARCH model\n",
    "model = arch_model(returns, vol='ARCH', p=1)\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Print the model summary\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'init mu': -0.004761812095238095, 'init alpha0': 0.00022024427545202675, 'init alpha1': 0, 'init max_log_likelihood': 58.620410291243196}\n",
      "max_log_likelihood 75.74047540068054\n",
      "{'mu': -0.00825835900119399, 'alpha0': 0.00031975580147541676, 'alpha1': -0.2481686188042993, 'max_log_likelihood': 75.74047540068054}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BenjaminMoiroud\\AppData\\Local\\Temp\\ipykernel_19792\\3864532026.py:25: RuntimeWarning: invalid value encountered in log\n",
      "  return -0.5 * np.log(2 * np.pi * variance) - (residual ** 2) / (2 * variance)\n",
      "C:\\Users\\BenjaminMoiroud\\AppData\\Local\\Temp\\ipykernel_19792\\3864532026.py:25: RuntimeWarning: divide by zero encountered in log\n",
      "  return -0.5 * np.log(2 * np.pi * variance) - (residual ** 2) / (2 * variance)\n",
      "C:\\Users\\BenjaminMoiroud\\AppData\\Local\\Temp\\ipykernel_19792\\3864532026.py:25: RuntimeWarning: divide by zero encountered in divide\n",
      "  return -0.5 * np.log(2 * np.pi * variance) - (residual ** 2) / (2 * variance)\n",
      "C:\\Users\\BenjaminMoiroud\\AppData\\Local\\Temp\\ipykernel_19792\\3864532026.py:25: RuntimeWarning: invalid value encountered in subtract\n",
      "  return -0.5 * np.log(2 * np.pi * variance) - (residual ** 2) / (2 * variance)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "class ARCHModel:\n",
    "    def __init__(self, returns):\n",
    "        self.returns = np.array(returns)\n",
    "        self.conditionnal_variance = None\n",
    "        self.mu = None\n",
    "        self.alpha0 = None\n",
    "        self.alpha1 = None\n",
    "        self.max_log_likelihood = None\n",
    "       \n",
    "    \n",
    "    def _compute_residuals(self, mu):\n",
    "        residuals = self.returns - mu\n",
    "        shift_residuals = np.roll(residuals, 1)\n",
    "        shift_residuals[0] = 0\n",
    "        return residuals, shift_residuals \n",
    "    \n",
    "    def _compute_conditional_variance(self, alpha0, alpha1, shift_residuals):\n",
    "        variances = alpha0 + alpha1 * shift_residuals ** 2\n",
    "        return variances\n",
    "    \n",
    "    def _log_normal_density(self, residual , variance):\n",
    "        return -0.5 * np.log(2 * np.pi * variance) - (residual ** 2) / (2 * variance)\n",
    "\n",
    "    def _mle_arch(self, params):\n",
    "        mu, alpha0, alpha1 = params\n",
    "        residuals, shift_residuals = self._compute_residuals(mu)\n",
    "        conditionnal_variance = self._compute_conditional_variance(alpha0, alpha1, shift_residuals)\n",
    "        log_likelihood = self._log_normal_density(residuals, conditionnal_variance)\n",
    "        return -np.sum(log_likelihood)\n",
    "    \n",
    "    def fit(self):\n",
    "        mu =  np.mean( self.returns);\n",
    "        alpha0 =  np.var(self.returns);\n",
    "        alpha1 = 0  \n",
    "        \n",
    "        initial_params = [mu, alpha0, alpha1]\n",
    "        self.max_log_likelihood = -self._mle_arch(initial_params)\n",
    "\n",
    "        print( {\n",
    "            \"init mu\": mu,\n",
    "            \"init alpha0\": alpha0,\n",
    "            \"init alpha1\": alpha1,\n",
    "            \"init max_log_likelihood\": self.max_log_likelihood\n",
    "        })\n",
    "\n",
    "        \n",
    "        bounds = [(None, None), (None, None), (None, None)] \n",
    "        \n",
    "        # Minimize the negative log-likelihood\n",
    "        result = minimize(self._mle_arch, initial_params, bounds=bounds, method='Nelder-Mead') \n",
    "        if result.success:\n",
    "            self.mu, self.alpha0, self.alpha1 = result.x\n",
    "            self.max_log_likelihood = -result.fun  # Store the maximum log-likelihood\n",
    "        else:\n",
    "            raise ValueError(\"Optimization failed: \" + result.message)\n",
    "\n",
    "        self.mu, self.alpha0, self.alpha1 = result.x\n",
    "        self.max_log_likelihood = -result.fun  # Store the maximum log-likelihood\n",
    "        print(\"max_log_likelihood\", self.max_log_likelihood)\n",
    "\n",
    "    def summary(self):\n",
    "        return {\n",
    "            \"mu\": self.mu,\n",
    "            \"alpha0\": self.alpha0,\n",
    "            \"alpha1\": self.alpha1,\n",
    "            \"max_log_likelihood\": self.max_log_likelihood\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "# Initialize arrays\n",
    "returns = [0.003146575,-0.017723909,0.007254689,0.014989689,\n",
    "0.011250607,0.003328635,-0.005409767,0.007332392,0.001700427,\n",
    "0.006432783,-0.001627508,0.001867275,-0.002928821,0.004717681,\n",
    "-0.003839112,-0.010494486,-0.033525076,-0.030286122,-0.003772137,\n",
    "-0.04415351,-0.008258359]\n",
    "\n",
    "# Create the ARCH model and fit it\n",
    "model = ARCHModel(returns)\n",
    "model.fit()\n",
    "\n",
    "# Print the model summary\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
